{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "# Assignment 3 Ungraded Sections - Part 1: BERT Loss Model \n",
    "\n",
    "Welcome to the part 1 of testing the models for this week's assignment. We will perform decoding using the BERT Loss model. In this notebook we'll use an input, mask (hide) random word(s) in it and see how well we get the \"Target\" answer(s). \n",
    "\n",
    "## Colab\n",
    "\n",
    "Since this ungraded lab takes a lot of time to run on coursera, as an alternative we have a colab prepared for you.\n",
    "\n",
    "[BERT Loss Model Colab](https://drive.google.com/file/d/1EHAbMnW6u-GqYWh5r3Z8uLbz4KNpKOAv/view?usp=sharing)\n",
    "\n",
    "- If you run into a page that looks similar to the one below, with the option `Open with`, this would mean you need to download the `Colaboratory` app. You can do so by `Open with -> Connect more apps -> in the search bar write \"Colaboratory\" -> install`\n",
    "\n",
    "<img src = \"colab_help_1.png\"> \n",
    "\n",
    "- After installation it should look like this. Click on `Open with Google Colaboratory`\n",
    "\n",
    "<img src = \"colab_help_2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db6LQW5cMSgx"
   },
   "source": [
    "## Outline\n",
    "\n",
    "- [Overview](#0)\n",
    "- [Part 1: Getting ready](#1)\n",
    "- [Part 2: BERT Loss](#2)\n",
    "    - [2.1 Decoding](#2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysxogfC1M158"
   },
   "source": [
    "<a name='0'></a>\n",
    "### Overview\n",
    "\n",
    "In this notebook you will:\n",
    "* Implement the Bidirectional Encoder Representation from Transformer (BERT) loss. \n",
    "* Use a pretrained version of the model you created in the assignment for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# Part 1: Getting ready\n",
    "\n",
    "Run the code cells below to import the necessary libraries and to define some functions which will be useful for decoding. The code and the functions are the same as the ones you previsouly ran on the graded assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import string\n",
    "import ast\n",
    "import numpy as np\n",
    "import trax \n",
    "from trax.supervised import decoding\n",
    "import textwrap \n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_jsons = list(map(ast.literal_eval, open('data.txt')))\n",
    "\n",
    "natural_language_texts = [example_json['text'] for example_json in example_jsons]\n",
    "\n",
    "PAD, EOS, UNK = 0, 1, 2\n",
    "\n",
    "def detokenize(np_array):\n",
    "    return trax.data.detokenize(\n",
    "        np_array,\n",
    "        vocab_type='sentencepiece',\n",
    "        vocab_file='sentencepiece.model',\n",
    "        vocab_dir='.')\n",
    "\n",
    "\n",
    "def tokenize(s):\n",
    "    return next(trax.data.tokenize(\n",
    "        iter([s]),\n",
    "        vocab_type='sentencepiece',\n",
    "        vocab_file='sentencepiece.model',\n",
    "        vocab_dir='.'))\n",
    " \n",
    "    \n",
    "vocab_size = trax.data.vocab_size(\n",
    "    vocab_type='sentencepiece',\n",
    "    vocab_file='sentencepiece.model',\n",
    "    vocab_dir='.')\n",
    "\n",
    "\n",
    "def get_sentinels(vocab_size, display=False):\n",
    "    sentinels = {}\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = detokenize([vocab_size - i]) \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'    \n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "    return sentinels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinels = get_sentinels(vocab_size, display=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Internațional': '<Z>',\n",
       " 'erwachsene': '<Y>',\n",
       " 'Cushion': '<X>',\n",
       " 'imunitar': '<W>',\n",
       " 'Intellectual': '<V>',\n",
       " 'traditi': '<U>',\n",
       " 'disguise': '<T>',\n",
       " 'exerce': '<S>',\n",
       " 'nourishe': '<R>',\n",
       " 'predominant': '<Q>',\n",
       " 'amitié': '<P>',\n",
       " 'erkennt': '<O>',\n",
       " 'dimension': '<N>',\n",
       " 'inférieur': '<M>',\n",
       " 'refugi': '<L>',\n",
       " 'cheddar': '<K>',\n",
       " 'unterlieg': '<J>',\n",
       " 'garanteaz': '<I>',\n",
       " 'făcute': '<H>',\n",
       " 'réglage': '<G>',\n",
       " 'pedepse': '<F>',\n",
       " 'Germain': '<E>',\n",
       " 'distinctly': '<D>',\n",
       " 'Schraub': '<C>',\n",
       " 'emanat': '<B>',\n",
       " 'trimestre': '<A>',\n",
       " 'disrespect': '<z>',\n",
       " 'Erasmus': '<y>',\n",
       " 'Australia': '<x>',\n",
       " 'permeabil': '<w>',\n",
       " 'deseori': '<v>',\n",
       " 'manipulated': '<u>',\n",
       " 'suggér': '<t>',\n",
       " 'corespund': '<s>',\n",
       " 'nitro': '<r>',\n",
       " 'oyons': '<q>',\n",
       " 'Account': '<p>',\n",
       " 'échéan': '<o>',\n",
       " 'laundering': '<n>',\n",
       " 'genealogy': '<m>',\n",
       " 'QuickBooks': '<l>',\n",
       " 'constituted': '<k>',\n",
       " 'Fertigung': '<j>',\n",
       " 'goutte': '<i>',\n",
       " 'regulă': '<h>',\n",
       " 'overwhelmingly': '<g>',\n",
       " 'émerg': '<f>',\n",
       " 'broyeur': '<e>',\n",
       " 'povești': '<d>',\n",
       " 'emulator': '<c>',\n",
       " 'halloween': '<b>',\n",
       " 'combustibil': '<a>'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_decode(encoded_str_list, sentinels=sentinels):\n",
    "    # If already a string, just do the replacements.\n",
    "    if isinstance(encoded_str_list, (str, bytes)):\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = encoded_str_list.replace(token, char)\n",
    "        return encoded_str_list\n",
    "     \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(detokenize(encoded_str_list))\n",
    "\n",
    "\n",
    "inputs_targets_pairs = []\n",
    "\n",
    "# here you are reading already computed input/target pairs from a file\n",
    "with open ('inputs_targets_pairs_file.txt', 'rb') as fp:\n",
    "    inputs_targets_pairs = pickle.load(fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "inputs:\n",
      "Beginners BBQ <Z> Taking <Y> in Missoula! <X> want to get better <W>\n",
      "making delicious <V>? You will have the opportunity, put this on <U>\n",
      "calendar now <T> Thursday, September 22nd<S> World Class BBQ Champion,\n",
      "Tony Balay from Lonestar Smoke Rangers. He<R> be <Q> a beginner<P>\n",
      "class for everyone <O> wants to<N> better <M> their <L> skills. He\n",
      "will teach you <K> you need to know <J> compete in  <I> KCBS BBQ\n",
      "competition, including techniques, recipes,<H>s, meat selection<G>\n",
      "trimming, plus smoker <F> information. The cost to be in the class is\n",
      "$35 per person<E> for spectator<D> is free. Included in the cost will\n",
      "be either a t-shirt or apron and you will<C> tasting samples of each\n",
      "meat that <B>.\n",
      "\n",
      "targets:\n",
      "<Z> Class <Y> Place <X> Do you <W> at <V> BBQ <U> your <T>.<S> join<R>\n",
      "will <Q> teaching<P> level <O> who<N> get <M> with <L> culinary <K>\n",
      "everything <J> to <I>a<H> timeline<G> and <F> and fire<E>, and<D>s\n",
      "it<C> be <B> is prepared\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[2]\n",
      "inputs:\n",
      "Discussion <Z> ' <Y> X Lion (10.7)' started by  <X>xboi87, Jan <W>\n",
      "2012. I've got a 500gb <V> drive and  <U> 240gb SSD <T> When trying to\n",
      "restore using disk utility i'm given the<S>Not enough space<R> disk\n",
      "___ <Q> to restore<P> But I shouldn't have to do that!!! <O> or<N>s\n",
      "before resorting to the <M>? Use <L> Copy <K>ner to copy one drive to\n",
      "the other. <J>'ve done this several times <I> larger<H>D<G> smaller\n",
      "SSD and I wound up with a bootable SSD drive. One step you have to\n",
      "remember not to skip is <F> use Disk Utility to partition the SSD as\n",
      "GUID partition scheme HFS+<E> doing the<D>ne<C> If it came Apple\n",
      "Partition Scheme, even if you let CCC do the  <B>e <A> the resulting\n",
      "<z> won' <y> be bootable<x> CCC<w> works in \"file mode\" and it can\n",
      "easily copy a larger drive (that's mostly empty) onto<v> drive.<u> you\n",
      "tell CCC to clone <t>a drive <s> did NOT boot from, it can work in<r>\n",
      "copy mode where the destination drive must be the same size or larger\n",
      "than<q> drive you are cloning from<p>if I recall). I've actually done\n",
      "<o> somehow <n> Disk Utility several times <m>booting from <l>a\n",
      "different drive (<k> even the dvd) so not running <j> utility from the\n",
      "drive your cloning) and had it<i> just fine from larger to smaller\n",
      "bootable clone. Definitely<h> drive <g>ning to first, as bootable\n",
      "Apple <f>.. Thanks for pointing this out<e> only experience using DU\n",
      "to go larger to smaller was when I was trying to make <d>a <c> install\n",
      "<b> I was unable to restore InstallESD.d <a>g Théâtre Keep 4 GB USB\n",
      "stick but of course the reason that wouldndürftigt fit isutti was\n",
      "slightly more than 4  Carolyn of data.\n",
      "\n",
      "targets:\n",
      "<Z> in <Y>Mac OS <X>a <W> 20, <V> internal <U>a <T>.<S> error \"<R> on\n",
      "<Q>_<P>\" <O> Any ideas<N> workaround <M> above <L> Carbon <K> Clo <J>\n",
      "I <I> going from<H> HD<G> to <F> to<E> before<D> clo<C>. <B>clon <A>,\n",
      "<z> drive <y>t<x>.<w> usually<v> a smaller<u> If <t>  <s> you<r>\n",
      "block<q> the<p> ( <o> this <n> on <m> ( <l> <k>or <j> disk<i> work<h>\n",
      "format the<g>clo <f> etc<e>. My <d>  <c> Lion <b> stick and <a>m\n",
      "Théâtre toKeepadürftig'utti there CarolynGB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[3]\n",
      "inputs:\n",
      "Fo <Z> plaid ly <Y> and <X>dex shortall with metallic slinky insets.\n",
      "Attached metallic elastic <W> with O-ring. <V>band <U>. Great hip hop\n",
      "<T> dance costume. Made in the USA.\n",
      "\n",
      "targets:\n",
      "<Z>il <Y>cra <X> span <W> belt <V> Head <U> included <T> or jazz\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[4]\n",
      "inputs:\n",
      "How many back <Z>s per day for <Y> site? Discussion in 'Black Hat SEO\n",
      "<X> by Omoplat <W>, Dec 3, 2010. 1) <V> a newly created site, what's\n",
      "the max # back <U>s per day I should do to be <T>? 2) how long do I\n",
      "have to let my site age before I can start<S> blinks? I did about <R>\n",
      "profiles every 24 hours <Q> 10 days for one of<P> sites which had a\n",
      "brand new domain. There is three backlinks for <O> of these<N> profile\n",
      "so thats 18 000 backlinks <M> 24 hours and nothing happened in terms\n",
      "of being penalized or sandboxed. This is now <L> 3 <K> ago and the\n",
      "site is ranking on first page for a lot of my targeted keywords <J>\n",
      "build more you can in starting but <I> manual<H> and not spammy\n",
      "type<G> manual + relevant to the <F>.. then after 1 month you can make\n",
      "a big<E>.. Wow, dude, you built 18k backlinks a day on a brand new<D>?\n",
      "How quickly<C> rank up? What <B> of competition/searches did those\n",
      "keywords have?\n",
      "\n",
      "targets:\n",
      "<Z>link <Y> new <X>' started <W>a <V> for <U>link <T> safe<S> making\n",
      "more<R>6000 forum <Q> for<P> my <O> every<N> forum <M> every <L> maybe\n",
      "<K> months <J>. <I> do<H> submission<G> means <F> post<E> blast<D>\n",
      "site<C> did you <B> kind\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[5]\n",
      "inputs:\n",
      "The Denver Board of Education opened the 2017-18 school year with an\n",
      "update on projects that include new construction, upgrades, heat\n",
      "mitigation and quality <Z>. We are excited <Y> students will be the\n",
      "<X> of a four year, <W>72 million <V> Obligation Bond. Since the\n",
      "passage of <U> bond, <T> construction team has worked to<S> the\n",
      "projects over the four-year term of<R> bond. Denver <Q> on Tuesday\n",
      "approved<P> and mill funding measures for students in <O> Public\n",
      "Schools, agreeing to invest $5<N> million in bond funding to build and\n",
      "improve schools and $5 <M> million in <L> dollars to support proven\n",
      "initiatives, such as early literacy. Denver voters say yes to bond and\n",
      "mill levy funding support <K> DPS students and schools. Click to learn\n",
      "<J> about the details <I> voter-approved bond measure. Denver voters\n",
      "on Nov. 8 approved bond and mill funding measures for DPS students and\n",
      "schools. Learn<H> about what’s included<G> the mill levy measure.\n",
      "\n",
      "targets:\n",
      "<Z> learning environments <Y> that Denver <X> beneficiaries <W> $5 <V>\n",
      "General <U> the <T> our<S> schedule<R> the <Q> voters<P> bond <O>\n",
      "Denver<N>72 <M>6.6 <L> operating <K> for <J> more <I> of the<H>\n",
      "more<G> in\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_input_target_pairs(inputs_targets_pairs):\n",
    "    for i, inp_tgt_pair in enumerate(inputs_targets_pairs, 1):\n",
    "        inps, tgts = inp_tgt_pair\n",
    "        inps, tgts = pretty_decode(inps), pretty_decode(tgts)\n",
    "        print(f'[{i}]\\n'\n",
    "              f'inputs:\\n{wrapper.fill(text=inps)}\\n\\n'\n",
    "              f'targets:\\n{wrapper.fill(text=tgts)}\\n\\n\\n\\n')\n",
    "    \n",
    "display_input_target_pairs(inputs_targets_pairs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: BERT Loss\n",
    "\n",
    "Now that you created the encoder, we will not make you train it. Training it could easily cost you a few days depending on which GPUs/TPUs you are using. Very few people train the full transformer from scratch. Instead, what the majority of people do, they load in a pretrained model, and they fine tune it on a specific task. That is exactly what you are about to do. Let's start by initializing and then loading in the model. \n",
    "\n",
    "Initialize the model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model = trax.models.Transformer(\n",
    "    d_ff = 4096,\n",
    "    d_model = 1024,\n",
    "    max_len = 2048,\n",
    "    n_heads = 16,\n",
    "    dropout = 0.1,\n",
    "    input_vocab_size = 32000,\n",
    "    n_encoder_layers = 24,\n",
    "    n_decoder_layers = 24,\n",
    "    mode='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Serial in module trax.layers.combinators object:\n",
      "\n",
      "class Serial(trax.layers.base.Layer)\n",
      " |  Serial(*sublayers, name=None, sublayers_to_print=None)\n",
      " |  \n",
      " |  Combinator that applies layers serially (by function composition).\n",
      " |  \n",
      " |  This combinator is commonly used to construct deep networks, e.g., like this::\n",
      " |  \n",
      " |      mlp = tl.Serial(\n",
      " |        tl.Dense(128),\n",
      " |        tl.Relu(),\n",
      " |        tl.Dense(10),\n",
      " |        tl.LogSoftmax()\n",
      " |      )\n",
      " |  \n",
      " |  A Serial combinator uses stack semantics to manage data for its sublayers.\n",
      " |  Each sublayer sees only the inputs it needs and returns only the outputs it\n",
      " |  has generated. The sublayers interact via the data stack. For instance, a\n",
      " |  sublayer k, following sublayer j, gets called with the data stack in the\n",
      " |  state left after layer j has applied. The Serial combinator then:\n",
      " |  \n",
      " |    - takes n_in items off the top of the stack (n_in = k.n_in) and calls\n",
      " |      layer k, passing those items as arguments; and\n",
      " |  \n",
      " |    - takes layer k's n_out return values (n_out = k.n_out) and pushes\n",
      " |      them onto the data stack.\n",
      " |  \n",
      " |  A Serial instance with no sublayers acts as a special-case (but useful)\n",
      " |  1-input 1-output no-op.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Serial\n",
      " |      trax.layers.base.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *sublayers, name=None, sublayers_to_print=None)\n",
      " |      Creates a partially initialized, unconnected layer instance.\n",
      " |      \n",
      " |      Args:\n",
      " |        n_in: Number of inputs expected by this layer.\n",
      " |        n_out: Number of outputs promised by this layer.\n",
      " |        name: Class-like name for this layer; for use when printing this layer.\n",
      " |        sublayers_to_print: Sublayers to display when printing out this layer;\n",
      " |          By default (when None) we display all sublayers.\n",
      " |  \n",
      " |  forward(self, xs)\n",
      " |      Computes this layer's output as part of a forward pass through the model.\n",
      " |      \n",
      " |      Authors of new layer subclasses should override this method to define the\n",
      " |      forward computation that their layer performs. Use `self.weights` to access\n",
      " |      trainable weights of this layer. If you need to use local non-trainable\n",
      " |      state or randomness, use `self.rng` for the random seed (no need to set it)\n",
      " |      and use `self.state` for non-trainable state (and set it to the new value).\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Zero or more input tensors, packaged as described in the `Layer`\n",
      " |            class docstring.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Zero or more output tensors, packaged as described in the `Layer` class\n",
      " |        docstring.\n",
      " |  \n",
      " |  init_weights_and_state(self, input_signature)\n",
      " |      Initializes weights and state for inputs with the given signature.\n",
      " |      \n",
      " |      Authors of new layer subclasses should override this method if their layer\n",
      " |      uses trainable weights or non-trainable state. To initialize trainable\n",
      " |      weights, set `self.weights` and to initialize non-trainable state,\n",
      " |      set `self.state` to the intended value.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: A `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or a list/tuple of `ShapeDtype` instances; signatures of inputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __call__(self, x, weights=None, state=None, rng=None)\n",
      " |      Makes layers callable; for use in tests or interactive settings.\n",
      " |      \n",
      " |      This convenience method helps library users play with, test, or otherwise\n",
      " |      probe the behavior of layers outside of a full training environment. It\n",
      " |      presents the layer as callable function from inputs to outputs, with the\n",
      " |      option of manually specifying weights and non-parameter state per individual\n",
      " |      call. For convenience, weights and non-parameter state are cached per layer\n",
      " |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,\n",
      " |      and acquiring non-empty values either by initialization or from values\n",
      " |      explicitly provided via the weights and state keyword arguments.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: Weights or `None`; if `None`, use self's cached weights value.\n",
      " |        state: State or `None`; if `None`, use self's cached state value.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Zero or more output tensors, packaged as described in the `Layer` class\n",
      " |        docstring.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  backward(self, inputs, output, grad, weights, state, new_state, rng)\n",
      " |      Custom backward pass to propagate gradients in a custom way.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensors; can be a (possibly nested) tuple.\n",
      " |        output: The result of running this layer on inputs.\n",
      " |        grad: Gradient signal computed based on subsequent layers; its structure\n",
      " |            and shape must match output.\n",
      " |        weights: This layer's weights.\n",
      " |        state: This layer's state prior to the current forward pass.\n",
      " |        new_state: This layer's state after the current forward pass.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |      \n",
      " |      Returns:\n",
      " |        The custom gradient signal for the input. Note that we need to return\n",
      " |        a gradient for each argument of forward, so it will usually be a tuple\n",
      " |        of signals: the gradient for inputs and weights.\n",
      " |  \n",
      " |  init(self, input_signature, rng=None, use_cache=False)\n",
      " |      Initializes weights/state of this layer and its sublayers recursively.\n",
      " |      \n",
      " |      Initialization creates layer weights and state, for layers that use them.\n",
      " |      It derives the necessary array shapes and data types from the layer's input\n",
      " |      signature, which is itself just shape and data type information.\n",
      " |      \n",
      " |      For layers without weights or state, this method safely does nothing.\n",
      " |      \n",
      " |      This method is designed to create weights/state only once for each layer\n",
      " |      instance, even if the same layer instance occurs in multiple places in the\n",
      " |      network. This enables weight sharing to be implemented as layer sharing.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: `ShapeDtype` instance (if this layer takes one input)\n",
      " |            or list/tuple of `ShapeDtype` instances.\n",
      " |        rng: Single-use random number generator (JAX PRNG key), or `None`;\n",
      " |            if `None`, use a default computed from an integer 0 seed.\n",
      " |        use_cache: If `True`, and if this layer instance has already been\n",
      " |            initialized elsewhere in the network, then return special marker\n",
      " |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.\n",
      " |            Else return this layer's newly initialized weights and state.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `(weights, state)` tuple.\n",
      " |  \n",
      " |  init_from_file(self, file_name, weights_only=False, input_signature=None)\n",
      " |      Initializes this layer and its sublayers from a pickled checkpoint.\n",
      " |      \n",
      " |      In the common case (`weights_only=False`), the file must be a gziped pickled\n",
      " |      dictionary containing items with keys `'flat_weights', `'flat_state'` and\n",
      " |      `'input_signature'`, which are used to initialize this layer.\n",
      " |      If `input_signature` is specified, it's used instead of the one in the file.\n",
      " |      If `weights_only` is `True`, the dictionary does not need to have the\n",
      " |      `'flat_state'` item and the state it not restored either.\n",
      " |      \n",
      " |      Args:\n",
      " |        file_name: Name/path of the pickeled weights/state file.\n",
      " |        weights_only: If `True`, initialize only the layer's weights. Else\n",
      " |            initialize both weights and state.\n",
      " |        input_signature: Input signature to be used instead of the one from file.\n",
      " |  \n",
      " |  output_signature(self, input_signature)\n",
      " |      Returns output signature this layer would give for `input_signature`.\n",
      " |  \n",
      " |  pure_fn(self, x, weights, state, rng, use_cache=False)\n",
      " |      Applies this layer as a pure function with no optional args.\n",
      " |      \n",
      " |      This method exposes the layer's computation as a pure function. This is\n",
      " |      especially useful for JIT compilation. Do not override, use `forward`\n",
      " |      instead.\n",
      " |      \n",
      " |      Args:\n",
      " |        x: Zero or more input tensors, packaged as described in the `Layer` class\n",
      " |            docstring.\n",
      " |        weights: A tuple or list of trainable weights, with one element for this\n",
      " |            layer if this layer has no sublayers, or one for each sublayer if\n",
      " |            this layer has sublayers. If a layer (or sublayer) has no trainable\n",
      " |            weights, the corresponding weights element is an empty tuple.\n",
      " |        state: Layer-specific non-parameter state that can update between batches.\n",
      " |        rng: Single-use random number generator (JAX PRNG key).\n",
      " |        use_cache: if `True`, cache weights and state in the layer object; used\n",
      " |          to implement layer sharing in combinators.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)\n",
      " |        promised by this layer, and are packaged as described in the `Layer`\n",
      " |        class docstring.\n",
      " |  \n",
      " |  weights_and_state_signature(self, input_signature)\n",
      " |      Return a pair containing the signatures of weights and state.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from trax.layers.base.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  has_backward\n",
      " |      Returns `True` if this layer provides its own custom backward pass code.\n",
      " |      \n",
      " |      A layer subclass that provides custom backward pass code (for custom\n",
      " |      gradients) must override this method to return `True`.\n",
      " |  \n",
      " |  n_in\n",
      " |      Returns how many tensors this layer expects as input.\n",
      " |  \n",
      " |  n_out\n",
      " |      Returns how many tensors this layer promises as output.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this layer.\n",
      " |  \n",
      " |  rng\n",
      " |      Returns a single-use random number generator without advancing it.\n",
      " |  \n",
      " |  state\n",
      " |      Returns a tuple containing this layer's state; may be empty.\n",
      " |      \n",
      " |      If the layer has sublayers, the state by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing sublayer states.\n",
      " |      Note that in this case self._state only marks which ones are shared.\n",
      " |  \n",
      " |  sublayers\n",
      " |      Returns a tuple containing this layer's sublayers; may be empty.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns this layer's weights.\n",
      " |      \n",
      " |      Depending on the layer, the weights can be in the form of:\n",
      " |      \n",
      " |        - an empty tuple\n",
      " |        - a tensor (ndarray)\n",
      " |        - a nested structure of tuples and tensors\n",
      " |      \n",
      " |      If the layer has sublayers, the weights by convention will be\n",
      " |      a tuple of length `len(sublayers)` containing the weights of sublayers.\n",
      " |      Note that in this case self._weights only marks which ones are shared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load in the model\n",
    "# this takes about 1 minute\n",
    "shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)  # Needed in predict mode.\n",
    "model.init_from_file('model.pkl.gz',\n",
    "                     weights_only=True, input_signature=(shape11, shape11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HuTyft5EBQK6"
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 Decoding\n",
    "\n",
    "Now you will use one of the `inputs_targets_pairs` for input and as target. Next you will use the `pretty_decode` to output the input and target. The code to perform all of this has been provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "gPggKamNBZxJ",
    "outputId": "4514c865-7534-4ce8-a339-2a4030bc6fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretty_decoded input: \n",
      "\n",
      " Fo <Z> plaid ly <Y> and <X>dex shortall with metallic slinky insets. Attached metallic elastic <W> with O-ring. <V>band <U>. Great hip hop <T> dance costume. Made in the USA.\n",
      "\n",
      "pretty_decoded target: \n",
      "\n",
      " <Z>il <Y>cra <X> span <W> belt <V> Head <U> included <T> or jazz\n",
      "\n",
      "c4_input:\n",
      "\n",
      " [4452, 31999, 30772, 3, 120, 31998, 11, 31997, 26, 994, 710, 1748, 28, 18813, 3, 7, 4907, 63, 16, 2244, 7, 5, 28416, 15, 26, 18813, 15855, 31996, 28, 411, 18, 1007, 5, 31995, 3348, 31994, 5, 1651, 5436, 13652, 31993, 2595, 11594, 5, 6465, 16, 8, 2312, 5]\n",
      "\n",
      "c4_target:\n",
      "\n",
      " [31999, 173, 31998, 2935, 31997, 8438, 31996, 6782, 31995, 3642, 31994, 1285, 31993, 42, 9948]\n",
      "15\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# using the 3rd example\n",
    "c4_input = inputs_targets_pairs[2][0]\n",
    "c4_target = inputs_targets_pairs[2][1]\n",
    "\n",
    "print('pretty_decoded input: \\n\\n', pretty_decode(c4_input))\n",
    "print('\\npretty_decoded target: \\n\\n', pretty_decode(c4_target))\n",
    "print('\\nc4_input:\\n\\n', c4_input)\n",
    "print('\\nc4_target:\\n\\n', c4_target)\n",
    "print(len(c4_target))\n",
    "print(len(pretty_decode(c4_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to decode.\n",
    "\n",
    "### Note: This will take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "id": "-I12YqxMTwgo",
    "outputId": "4e2399fa-7cbd-4ae3-8cee-6c97cbd277af",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Temperature is a parameter for sampling.\n",
    "#   # * 0.0: same as argmax, always pick the most probable token\n",
    "#   # * 1.0: sampling from the distribution (can sometimes say random things)\n",
    "#   # * values inbetween can trade off diversity and quality, try it out!\n",
    "output = decoding.autoregressive_sample(model, inputs=np.array(c4_input)[None, :],\n",
    "                                        temperature=0.0, max_length=5) # originally max_length = 50\n",
    "print(wrapper.fill(pretty_decode(output[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJh_Qw9G5jND"
   },
   "source": [
    "At this point the RAM is almost full, this happens because the model and the decoding is memory heavy. You can run decoding just once. Running it the second time with another example might give you an answer that makes no sense, or repetitive words. If that happens restart the runtime (see how to at the start of the notebook) and run all the cells again.\n",
    "\n",
    "You should also be aware that the quality of the decoding is not very good because max_length was downsized from 50 to 5 so that this runs faster within this environment. The colab version uses the original max_length so check that one for the actual decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C4W3-solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
